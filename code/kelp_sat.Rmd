---
title: "Tab 1 - Satellite Kelp Data"
author: "Conner Smith"
date: "2/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ncdf4)
library(sf)
library(raster)
library(rgdal)
library(here)
library(tmap)
library(stringr)
library(tidyverse)
```

```{r}
## Read in the dataset from: https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-sbc&identifier=74.

## This is time series data of kelp canopy using satellite imagery and will be updated regularly. The file is a .ns so we use the 'ncdf4' package. 

####### IMPORTANT NOTE
# Other users will have to download this file to their local machines as it is too large to upload to github directly 

nc_kelp_raw <- nc_open(here("data", "LandsatkelpBiomass_2021_v2_withmetadata.nc"))


year <-ncvar_get(nc_kelp_raw,"year")
quarter <- ncvar_get(nc_kelp_raw,"quarter")
  
lon <- ncvar_get(nc_kelp_raw,"longitude")
lat <- ncvar_get(nc_kelp_raw,"latitude")
biomass<-ncvar_get(nc_kelp_raw,"biomass") 


time<-data.frame(year,quarter) %>% 
   mutate(time_stamp = group_indices(., year, quarter))

# Now we have the time data in its own data frame thanks. 152 is the time stamp for Q4 of 2021. Each time_stamp has its own unique ID. 


df_li <- data.frame(lat,lon,biomass=data.frame(biomass)[,152]) %>%
  filter(!is.na(biomass)) %>%
  filter(lat>=33.847062&lat<=34.100458&lon>=-120.291726&lon<=-119.924374) %>%
  filter(biomass > 0) # too many values if 0s are included 

print(df_li)

write.csv(df_li, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\santa_cruz_kelp_2021.csv', row.names = FALSE)

# This is a test csv not in use by the app currently demonstrating how the subsets can be created. This is just data for the Fourth quarter of 2021 for Santa Rosa island. 


# This is an example of how this data can be converted into interactive tmaps 

kelp_sat_sf <- df_li %>% 
  st_as_sf(coords = c('lon', 'lat'))

st_crs(kelp_sat_sf) <- 4326


tmap_mode('view') 
tmap_kelp_sat <- 
  tm_shape(kelp_sat_sf) +
  tm_legend(title = "Santa Cruz Kelp Biomass in 2021 (kg)") +
  tm_dots('biomass', palette = 'BuGn')
tmap_kelp_sat

#This works! Kelp values for one quarter/year on santa rosa 
# Others could make fixed maps as well and use 'geom_tile' which can work with irregular grids such as this. 

######
# Here we begin wrangling data that will create the csv files that will be used by the app. 

sr_biomass <- data.frame(lat,lon, biomass=data.frame(biomass)) %>%
  filter(lat>=33.847062&lat<=34.100458&lon>=-120.291726&lon<=-119.924374) %>%
  mutate(cell_id = group_indices(., lat, lon)) %>% 
  pivot_longer(., 3:154, names_to = 'time_stamp', values_to = 'biomass') %>% 
  mutate_at("time_stamp", str_replace, "biomass.X", "") %>%
  drop_na() %>% 
  filter(biomass>0) %>% 
  transform(., time_stamp = as.numeric(time_stamp))

# Now we are getting somewhere. We have a tidy data set with time stamps and site IDs, left the coords in for now. Need to ask Nathan how to reference the time stamps across the data 
  
#the following is if we just want the site coordinates ("cell_id")
sr_sites <- data.frame(lat,lon, biomass=data.frame(biomass)) %>%
  filter(lat>=33.847062&lat<=34.100458&lon>=-120.291726&lon<=-119.924374) %>% 
  dplyr::select(lat,lon) %>% 
  mutate(cell_id = group_indices(., lat, lon))

# Here we have cell ids for all sites in the santa rosa area 
  
sr_biomass_complete <- 
  inner_join(sr_biomass, time, by = "time_stamp") %>% 
  group_by(lat, lon, cell_id, year) %>% 
  summarize(biomass = round(mean(biomass), 0))

write.csv(sr_biomass_complete, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\santa_rosa_kelp_all_years.csv', row.names = FALSE)

# This now shows all non zero/NA values for every year at every site. The time stamps have been assigned actual years and we have averaged the biomass for the year to remove the quarterly level observations 

# Because this isn't working with tmap, lets write a few example csv files to call in the shiny with certain years specified 

sr_biomass_2010 <- sr_biomass_complete %>% 
  filter(year == 2010)
write.csv(sr_biomass_2010, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\santa_rosa_kelp_2010.csv', row.names = FALSE)

sr_biomass_2015 <- sr_biomass_complete %>% 
  filter(year == 2015)
write.csv(sr_biomass_2015, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\santa_rosa_kelp_2015.csv', row.names = FALSE)

sr_biomass_2020 <- sr_biomass_complete %>% 
  filter(year == 2020)
write.csv(sr_biomass_2020, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\santa_rosa_kelp_2020.csv', row.names = FALSE)

# Now we have assigned site_id to each coordinate block for SR island, these are all of our files we will use in the app demo. 
```


## New Code Chunk for Coastline Coordinates, Same strategy as above. 

```{r}
#coordinates are rough estimates for a coastal box from gaviota to rincon 

coast_biomass <- data.frame(lat,lon, biomass=data.frame(biomass)) %>%
  filter(lat>=34.3712349&lat<=34.4747587&lon>=-120.2267407&lon<=-119.4778351) %>%
  mutate(cell_id = group_indices(., lat, lon)) %>% 
  pivot_longer(., 3:154, names_to = 'time_stamp', values_to = 'biomass') %>% 
  mutate_at("time_stamp", str_replace, "biomass.X", "") %>%
  drop_na() %>% 
  filter(biomass>0) %>% 
  transform(., time_stamp = as.numeric(time_stamp))

coast_sites <- data.frame(lat,lon, biomass=data.frame(biomass)) %>%
  filter(lat>=34.3712349&lat<=34.4747587&lon>=-120.2267407&lon<=-119.4778351) %>% 
  dplyr::select(lat,lon) %>% 
  mutate(cell_id = group_indices(., lat, lon))

coast_biomass_complete <- 
  inner_join(coast_biomass, time, by = "time_stamp") %>% 
  group_by(lat, lon, cell_id, year) %>% 
  summarize(biomass = round(mean(biomass), 0))

coast_sf_2010<- coast_biomass_complete %>% 
  dplyr::filter(year == '2010') %>% 
  st_as_sf(coords = c('lon', 'lat'))

st_crs(coast_sf_2010) <- 4326

tmap_mode('view') 

coast_2010 <-
  tm_shape(coast_sf_2010) +
  tm_legend(title = "Santa Cruz Kelp Biomass in 2021 (kg)") +
  tm_dots('biomass', palette = 'BuGn')
coast_2010


# THIS All works great, lets make some csv files

write.csv(coast_biomass_complete, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\coast_biomass_all_years.csv', row.names = FALSE)

coast_biomass_2010 <- coast_biomass_complete %>% 
  filter(year == 2010)
write.csv(coast_biomass_2010, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\coast_biomass_2010.csv', row.names = FALSE)

coast_biomass_2015 <- coast_biomass_complete %>% 
  filter(year == 2015)
write.csv(coast_biomass_2015, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\coast_biomass_2015.csv', row.names = FALSE)

coast_biomass_2020 <- coast_biomass_complete %>% 
  filter(year == 2020)
write.csv(coast_biomass_2020, 'C:\\Users\\conne\\Documents\\ESM 244\\Shiny\\ESM244_SBC_LTER_Shiny\\data\\coast_biomass_2020.csv', row.names = FALSE)


# Done making files for the analysis in the app. 
```

```{r}
# Others could try making static maps here, there are some .shp files already included in this repo.

#sb_map <- read_sf(here('data', 'coastal_map','3853-s3_2004_s3_coastal_zone.shp'))
```



